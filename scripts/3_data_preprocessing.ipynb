{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415f517b-656c-410d-a197-f465c8b598a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708ac0f0-af5b-4ac8-837d-b5003318305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_root = Path.cwd().parent\n",
    "dataset_dir = project_root / 'dataset'\n",
    "train_dir = dataset_dir / 'train'\n",
    "train_raw_images_dir = train_dir / 'raw_images'\n",
    "train_aug_images_dir = train_dir / 'aug_images'\n",
    "train_aug_labels_dir = train_dir / 'aug_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d06ec4-71b1-480a-b2f2-6b97514dd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmentation directory if it doesn't exist\n",
    "train_aug_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "train_aug_labels_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdc1d8b-b832-4694-bc5a-24a92a6b545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transformations = {\n",
    "    'Original': transforms.Compose([transforms.ToTensor()]),\n",
    "    'Flip Horizontal': transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]),\n",
    "    'Flip Vertical': transforms.Compose([transforms.RandomVerticalFlip(), transforms.ToTensor()]),\n",
    "    'Rotation': transforms.Compose([transforms.RandomRotation(30), transforms.ToTensor()]),\n",
    "    'Color Jitter': transforms.Compose([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5), transforms.ToTensor()]),\n",
    "    'Resized Crop': transforms.Compose([transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), transforms.ToTensor()]),\n",
    "    'Affine': transforms.Compose([transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), transforms.ToTensor()]),\n",
    "    'Grayscale': transforms.Compose([transforms.RandomGrayscale(p=0.5), transforms.ToTensor()]),\n",
    "    'Posterize': transforms.Compose([transforms.RandomPosterize(bits=4), transforms.ToTensor()]),\n",
    "    'Gaussian Blur': transforms.Compose([transforms.GaussianBlur(kernel_size=5), transforms.ToTensor()]),\n",
    "    'Perspective': transforms.Compose([transforms.RandomPerspective(distortion_scale=0.5, p=1.0, interpolation=3), transforms.ToTensor()]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e8a8bb-42e5-4036-aefa-ecef391717be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display transformed images\n",
    "def display_augmented_images(img, transforms_dict):\n",
    "    fig, axes = plt.subplots(2, len(transforms_dict) // 2, figsize=(15, 10))\n",
    "    axes = axes.ravel()  # Flatten axes for easier indexing\n",
    "    for i, (name, transform) in enumerate(transforms_dict.items()):\n",
    "        augmented_img = transform(img)\n",
    "        # Convert tensor back to PIL for viewing\n",
    "        augmented_img_pil = transforms.ToPILImage()(augmented_img)\n",
    "        axes[i].imshow(augmented_img_pil)\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d1cccc-59b0-4788-af7b-5f306ebaf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random image to apply different transformations\n",
    "image_filenames = os.listdir(train_raw_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fbfc13-08e1-4885-9a25-5c63fc68e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_filename = random.choice(image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60590853-4cea-49f3-901e-c15d180be551",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = train_raw_images_dir / random_image_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c739d9-6b0a-4730-bbd3-5d0f1507334a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display the augmented images with different transformations\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdisplay_augmented_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Optionally save the augmented images to your directory\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, transform \u001b[38;5;129;01min\u001b[39;00m transformations\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36mdisplay_augmented_images\u001b[1;34m(img, transforms_dict)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert tensor back to PIL for viewing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m augmented_img_pil \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToPILImage()(augmented_img)\n\u001b[1;32m----> 9\u001b[0m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(augmented_img_pil)\n\u001b[0;32m     10\u001b[0m axes[i]\u001b[38;5;241m.\u001b[39mset_title(name)\n\u001b[0;32m     11\u001b[0m axes[i]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "if image_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Display the augmented images with different transformations\n",
    "    display_augmented_images(img, transformations)\n",
    "\n",
    "    # Optionally save the augmented images to your directory\n",
    "    for name, transform in transformations.items():\n",
    "        augmented_img = transform(img)\n",
    "        save_path = train_aug_images_dir / f\"{name}_{random_image_filename}\"\n",
    "        augmented_img_pil = transforms.ToPILImage()(augmented_img)\n",
    "        augmented_img_pil.save(save_path)\n",
    "        print(f\"Saved {name} augmented image at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c1448-fee6-4d98-b43d-cbbc042db212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
